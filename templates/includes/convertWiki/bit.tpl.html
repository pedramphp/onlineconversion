				<article>
					<header>
						<h3>Bit</h3>
						<a href="http://en.wikipedia.org/wiki/Bit">Read more about Bit</a>
					</header>
					<section>
						<p>A bit is the basic unit of information in computing and digital communications. A bit can have only one of two values, and may therefore be physically implemented with a two-state device. The most common representation of these values are 0and1. The term bit is a contraction of binary digit.</p>
						<p>The two values can also be interpreted as logical values (true/false, yes/no), algebraic signs (+/âˆ’), activation states (on/off), or any other two-valued attribute. The correspondence between these values and the physical states of the underlying storage or device is a matter of convention, and different assignments may be used even within the same device or program. The length of a binary number may be referred to as its bit-length.</p>
						<p>In information theory, one bit is typically defined as the uncertainty of a binary random variable that is 0 or 1 with equal probability, or the information that is gained when the value of such a variable becomes known.</p>
						<p>In quantum computing, a quantum bit or qubit is a quantum system that can exist in superposition of two bit values, true and false.</p>
						<p>The symbol for bit, as a unit of information, is either simply bit (recommended by the ISO/IEC standard 80000-13 (2008)) or lowercase b (recommended by the IEEE 1541 Standard (2002)). A group of eight bits is commonly called one byte, but historically the size of the byte is not strictly defined.</p>
					</section>
				</article>